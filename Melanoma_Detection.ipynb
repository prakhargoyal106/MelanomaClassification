{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "jD96E7mri2SE",
    "outputId": "83b0ff8e-a7a0-46f6-a16b-8c1d10d81144"
   },
   "outputs": [],
   "source": [
    "! pip install efficientnet_pytorch torchtoolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "Yp_eMqUXf4HG",
    "outputId": "4a35b69d-c2bc-46cf-c00e-d29986005b6b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau , CyclicLR\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import os \n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import datetime\n",
    "import random\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from plotly.offline import iplot\n",
    "import cufflinks\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTBtjRig-Agb"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mv8q2FFfnrZA"
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('/content/drive/My Drive/Melanoma_Images/train.csv')\n",
    "test_csv = pd.read_csv('/content/drive/My Drive/Melanoma_Images/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "HL21I5XVsaIJ",
    "outputId": "a0b5d2cb-da4b-43b9-e6d3-9878f05e0708"
   },
   "outputs": [],
   "source": [
    "train_csv.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQxioZfEsg2j"
   },
   "source": [
    "First, Let's look for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "h3BPSS8bsTUt"
   },
   "outputs": [],
   "source": [
    "def missing(df):\n",
    "  \n",
    "  missing_per = (pd.isnull(df).sum()*100/len(df)).sort_values(ascending= False)\n",
    "  missing_count = pd.isnull(df).sum().sort_values(ascending= False)\n",
    "\n",
    "  missing_stats = pd.DataFrame({'Missing Values Percentage': missing_per, 'Missing Values Count': missing_count})\n",
    "  missing_data = missing_stats.loc[missing_stats['Missing Values Percentage'] > 0]\n",
    "\n",
    "  return missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "XYAm4oF6usF7",
    "outputId": "d2df1e1e-5f3c-4cee-82dd-145750754ed7"
   },
   "outputs": [],
   "source": [
    "missing(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "colab_type": "code",
    "id": "TN4OcoG6uu4r",
    "outputId": "3197a968-a395-4006-cf7f-00b794e21810"
   },
   "outputs": [],
   "source": [
    "missing(test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mz-lvxFQ08n2"
   },
   "source": [
    "Apart from site, our training dataset also have missing values in age & sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tL8Hh9Lz1S7l"
   },
   "source": [
    "Time for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "4dsTxlwZ00w6",
    "outputId": "3ca38df0-3ec0-4181-e605-64cc36515613"
   },
   "outputs": [],
   "source": [
    "# Let's plot some features\n",
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,5))\n",
    "\n",
    "sns.countplot(x = \"age_approx\", data = train_csv, ax = ax[0] )\n",
    "ax[0].set_title('Age Distribution in Train Data')\n",
    "\n",
    "sns.countplot(x= \"age_approx\", data = test_csv, ax= ax[1])\n",
    "ax[1].set_title('Age Distribution in Test Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "u3f7t3Sp4NSB",
    "outputId": "74b8eb75-78d7-4f35-a0f3-602159b5be3f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(20,5))\n",
    "\n",
    "sns.distplot(train_csv.patient_id.value_counts(), ax = ax[0], color= 'orangered', kde= True)\n",
    "ax[0].set_xlabel('Counts')\n",
    "ax[0].set_ylabel('freq')\n",
    "ax[0].set_title('Patient ID distribution in train data')\n",
    "\n",
    "sns.distplot(test_csv.patient_id.value_counts(), ax = ax[1], kde = True)\n",
    "ax[1].set_xlabel('Counts')\n",
    "ax[1].set_ylabel('freq')\n",
    "ax[1].set_title('Patient ID distribution in test data')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NetzV1sFMdu"
   },
   "outputs": [],
   "source": [
    "#let's see number of images we have for each patient\n",
    "train_csv.patient_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvsbaBH6jIF7"
   },
   "outputs": [],
   "source": [
    "test_csv.patient_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86bHdrFVj1gl"
   },
   "source": [
    "Patient Id: 'IP_3579794' in test data accounts for 240 images, approx 2% of test data (pretty big number as compared to other patient Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "u_Z6opr6kVTE",
    "outputId": "22276392-aaf1-4a8d-d9a4-b5077e84212c"
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1,2, figsize = (20,5))\n",
    "sns.countplot( x = 'benign_malignant', data = train_csv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "OOHYnarqmnu5",
    "outputId": "1c9c5241-3469-47f3-81bb-552cdd31c25a"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (20,5))\n",
    "\n",
    "sns.countplot( x = 'anatom_site_general_challenge', data = train_csv, ax = ax[0])\n",
    "ax[0].set_title('Sites in Train Data')\n",
    "\n",
    "sns.countplot(x = 'anatom_site_general_challenge', data = test_csv, ax = ax[1])\n",
    "ax[1].set_title('Sites in Test Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "cx3bD4eCpeFX",
    "outputId": "d366aab6-e0e1-44e8-9efc-35c206c57549"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize = (20,5))\n",
    "sns.countplot( x = 'anatom_site_general_challenge',hue = train_csv['benign_malignant'], data = train_csv)\n",
    "ax.set_title('Sites in Train Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "colab_type": "code",
    "id": "59qgdK3JmqUm",
    "outputId": "223a35ca-c5e5-4d5b-c293-a4cff1f2db06"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize = (20,10))\n",
    "sns.countplot( x = 'anatom_site_general_challenge',hue = train_csv['diagnosis'], data = train_csv)\n",
    "ax.set_title('Sites in Train Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "colab_type": "code",
    "id": "r3Ym_PV_rPQz",
    "outputId": "db67be63-520c-4eff-b73b-142a21b0e6dc"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (10,10))\n",
    "\n",
    "sns.countplot(x = 'sex',  data = train_csv, ax = ax[0])\n",
    "ax[0].set_title('Sex Distribution in Train Data')\n",
    "\n",
    "sns.countplot(x = 'sex', data = test_csv, ax = ax[1])\n",
    "ax[1].set_title('Sex Distribution in Test Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4DrirbApR9n"
   },
   "source": [
    "All the above graph suggests that our Data is highly imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFTGOxL2t8nx"
   },
   "outputs": [],
   "source": [
    "#Removing all the data with NaN\n",
    "train_1 = train_csv.loc[pd.notnull(train_csv['sex'])]\n",
    "train_2 = train_1.loc[pd.notnull(train_csv['age_approx'])]\n",
    "train_3 = train_2.loc[pd.notnull(train_csv['anatom_site_general_challenge'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VwuOAEGuB6Q"
   },
   "outputs": [],
   "source": [
    "site = pd.get_dummies(train_3['anatom_site_general_challenge'], prefix = 'site')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FxT-jTeR2lHb"
   },
   "outputs": [],
   "source": [
    "train_3['sex'] = train_3['sex'].map({'male':1, 'female':0 })\n",
    "test_csv['sex'] = test_csv['sex'].map({'male':1, 'female': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsW5vNLIATVO"
   },
   "outputs": [],
   "source": [
    "train_3  = pd.concat([train_3 , site] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1FxNVRuAIgM"
   },
   "outputs": [],
   "source": [
    "meta_features = ['sex', 'age_approx']  + [ f for f in site.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hD4ichWlKypO"
   },
   "outputs": [],
   "source": [
    "site_test = pd.get_dummies(test_csv['anatom_site_general_challenge'], prefix= 'site')\n",
    "test_csv = pd.concat([test_csv, site_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hcILFGg9Rm9s"
   },
   "outputs": [],
   "source": [
    "test_csv.drop(['anatom_site_general_challenge'], axis=1, inplace = True)\n",
    "train_3.drop(['anatom_site_general_challenge'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l8T23cAYSAgp"
   },
   "outputs": [],
   "source": [
    "test_csv.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FeCSHmc9SqLE",
    "outputId": "d12627c9-6032-4b78-f124-b2dd128a3f05"
   },
   "outputs": [],
   "source": [
    "train_3.patient_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NUXttJbtXZSD"
   },
   "outputs": [],
   "source": [
    "train_3['sex'] = train_csv['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPM9kx8dXpHv"
   },
   "outputs": [],
   "source": [
    "train_3['sex'] = train_3['sex'].map({'male':1, 'female': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "c3ulsyX6XQG7",
    "outputId": "0618a97e-ba3b-45d0-8fbc-c4f2d56b4c05"
   },
   "outputs": [],
   "source": [
    "train_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZgyZ6Trkiyw"
   },
   "source": [
    "In most of the image you will notice that there are hairs over the lesion area. We'll introduced a Data Augmentation technique to remove the hairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qM2e66E8fWk"
   },
   "outputs": [],
   "source": [
    "meta_features = ['sex', 'age_approx'] + [c for c in train_3.columns if 'site' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "iHM04EjO8wqH",
    "outputId": "5fb73d58-5e52-49fa-d43d-03b6b217be68"
   },
   "outputs": [],
   "source": [
    "meta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFxJlG-t4pjk"
   },
   "outputs": [],
   "source": [
    "c= cv2.imread('/content/drive/My Drive/Melanoma_Images/300x300/train/ISIC_0068279.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 840
    },
    "colab_type": "code",
    "id": "LkXUdkduioie",
    "outputId": "e8956872-25f4-47cb-b47e-4a704eff071d"
   },
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnZ0BpjYTJjO"
   },
   "outputs": [],
   "source": [
    "class RemoveHair:\n",
    "  \"\"\"\n",
    "      Remove Hairs from images\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    pass\n",
    "    \n",
    "  \n",
    "    \n",
    "  def __call__(self, image):\n",
    "\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(1, (17,17))\n",
    "\n",
    "    blackhat = cv2.morphologyEx(grayscale, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    _, threshold = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    final_image = cv2.inpaint(image, threshold, 1, cv2.INPAINT_TELEA)\n",
    "\n",
    "    return final_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4f8PYwC8rJnx"
   },
   "outputs": [],
   "source": [
    "class Microscope:\n",
    "\n",
    "  def __init__(self, p):\n",
    "    \n",
    "    self.p = p\n",
    "\n",
    "  def __call__(self, img):\n",
    "\n",
    "\n",
    "    if random.random() < self.p:\n",
    "      circle = cv2.circle((np.ones(img.shape) * 255).astype(np.uint8),\n",
    "                          (img.shape[0]//2, img.shape[1]//2),\n",
    "                          (random.randint(img.shape[0]//2 , img.shape[1]//2)),\n",
    "                          (0,0,0),\n",
    "                          -1)\n",
    "      mask  = circle - 255\n",
    "      img = np.multiply(img,mask)\n",
    "    \n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E9OgCR1GAomZ"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self, model, n_meta_features):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.model = model\n",
    "    if 'EfficientNet' in str(model.__class__):\n",
    "      self.model._fc = nn.Linear(in_features=1280, out_features=500, bias=True)\n",
    "    \n",
    "    self.meta = nn.Sequential(nn.Linear(n_meta_features, 500),\n",
    "                              nn.BatchNorm1d(500),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Dropout(p=0.2),\n",
    "                              nn.Linear(500,250),\n",
    "                              nn.BatchNorm1d(250),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Dropout(p=0.2))\n",
    "    \n",
    "    self.output = nn.Linear(500 + 250, 1)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "\n",
    "    x, meta = inputs\n",
    "    cnn_features = self.model(x)\n",
    "    meta_features = self.meta(meta)\n",
    "    features  = torch.cat((cnn_features, meta_features), dim = 1)\n",
    "    output = self.output(features)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HaY4JUcYj4pm"
   },
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "  \"\"\"\n",
    "    Our Dataset for Melanoma Classification\n",
    "    img_folder: Path to images directory\n",
    "    meta_features: Additional Data features to be used\n",
    "    df: Contains Meta_features\n",
    "    transforms: Data Augmentation Techniques to be applied\n",
    "  \"\"\"\n",
    "  def __init__(self, img_folder, df, meta_features = None, train = True, transforms = None ):\n",
    "    \n",
    "    super().__init__()\n",
    "\n",
    "    self.img_folder = img_folder\n",
    "    self.df = df\n",
    "    self.meta_features = meta_features\n",
    "    self.transforms = transforms\n",
    "    self.train = train\n",
    "    \n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "\n",
    "    img = os.path.join(self.img_folder , self.df.iloc[index]['image_name'] + '.jpg')\n",
    "    meta = np.array(self.df.iloc[index][meta_features].values, dtype= np.float32)\n",
    "    x = cv2.imread(img)\n",
    "\n",
    "    if self.transforms:\n",
    "      x = self.transforms(x)\n",
    "\n",
    "    if self.train:\n",
    "      y = self.df.iloc[index]['target']\n",
    "      return (x,meta) , y\n",
    "    else:\n",
    "      return (x,meta)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9opm2fXlv88J"
   },
   "outputs": [],
   "source": [
    "train_aug = transforms.Compose([RemoveHair(),\n",
    "                                Microscope(p=0.5),\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomVerticalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485,0.456,0.406], std = [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_aug = transforms.Compose([RemoveHair(),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean=[0.485,0.456,0.406], std = [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "                                \n",
    "                               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L5NU-KaSop3F",
    "outputId": "e54ef643-3e42-4a2e-850a-863e4f3a961c"
   },
   "outputs": [],
   "source": [
    "skf = GroupKFold(n_splits=10)\n",
    "model = EfficientNet.from_pretrained('efficientnet-b1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPgt2XrwKsnv"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VodJkaiV9GqJ"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model_path = 'model.pth'\n",
    "\n",
    "oof = np.zeros((len(train_3), 1))\n",
    "preds = torch.zeros((len(test_csv), 1), dtype = torch.float32, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AKPH--g_HLVq"
   },
   "outputs": [],
   "source": [
    "test = MelanomaDataset(img_folder = '/content/drive/My Drive/Melanoma_Images/300x300/test',\n",
    "                      df = test_csv,\n",
    "                      meta_features = meta_features,\n",
    "                      train = False,\n",
    "                      transforms = test_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "colab_type": "code",
    "id": "1PxsYDob9xOr",
    "outputId": "c95c318d-45cf-4323-9b27-f8f950710156"
   },
   "outputs": [],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X = np.zeros(len(train_3)), \n",
    "                                                      y = train_3['target'], \n",
    "                                                      groups= train_3['patient_id'].tolist()), \n",
    "                                                      1):\n",
    "\n",
    "  print('='*20, 'Fold', fold, '='*20 )\n",
    "  model = EfficientNet.from_pretrained('efficientnet-b1')\n",
    "  best_val = None\n",
    "  model = Net(model = model, n_meta_features = len(meta_features))\n",
    "\n",
    "  model = model.to(device)\n",
    "\n",
    "  optim = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "  scheduler = CyclicLR(optimizer = optim, base_lr = 0.001, max_lr=0.01)\n",
    "  criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "  train = MelanomaDataset(df = train_3.iloc[train_idx].reset_index(drop=True),\n",
    "                          img_folder = '/content/drive/My Drive/Melanoma_Images/300x300/train',\n",
    "                          meta_features = meta_features,\n",
    "                          train = True,\n",
    "                          transforms = train_aug)\n",
    "  \n",
    "  val = MelanomaDataset(df = train_3.iloc[val_idx].reset_index(drop=True),\n",
    "                        img_folder = '/content/drive/My Drive/Melanoma_Images/300x300/train',\n",
    "                        meta_features = meta_features,\n",
    "                        train = True,\n",
    "                        transforms = test_aug)\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  train_loader = DataLoader(dataset = train,\n",
    "                            batch_size = 32,\n",
    "                            shuffle = True,\n",
    "                            num_workers = 0)\n",
    "\n",
    "  \n",
    "  val_loader =  DataLoader(dataset = val,\n",
    "                            batch_size = 16,\n",
    "                            shuffle = False,\n",
    "                            num_workers = 0)\n",
    "  \n",
    "  \n",
    "  test_loader = DataLoader(dataset = test,\n",
    "                            batch_size = 16,\n",
    "                            shuffle = False,\n",
    "                            num_workers = 0)\n",
    "  \n",
    "  for epoch in range(epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for x,y in train_loader:\n",
    "      \n",
    "      x[0] = torch.tensor(x[0], device = device, dtype= torch.float32)\n",
    "      x[1] = torch.tensor(x[1], device = device, dtype= torch.float32)\n",
    "      y    = torch.tensor( y, device = device, dtype= torch.float32)\n",
    "\n",
    "      optim.zero_grad()\n",
    "      z = model(x)\n",
    "\n",
    "      loss = criterion(z, y.unsqueeze(1))\n",
    "      loss.backward()\n",
    "      \n",
    "      optim.step()\n",
    "\n",
    "      pred = torch.round(torch.sigmoid(z))\n",
    "      correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()\n",
    "      epoch_loss += loss.item()\n",
    "\n",
    "    train_acc = correct / len(train_idx)\n",
    "    model.eval()\n",
    "    val_preds = torch.zeros((len(val_idx), 1), dtype = torch.float32, device = device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "      for j, (x_val, y_val) in enumerate(val_loader):\n",
    "\n",
    "        x_val[0] = torch.tensor(x_val[0], device = device, dtype= torch.float32)\n",
    "        x_val[1] = torch.tensor(x_val[1], device = device, dtype= torch.float32)\n",
    "        y_val    = torch.tensor(y_val   , device = device, dtype= torch.float32)\n",
    "        \n",
    "        z_val = model(x_val)\n",
    "        val_pred = torch.sigmoid(z_val)\n",
    "        val_preds[j*x_val[0].shape[0]:j*x_val[0].shape + x_val[0].shape[0]] = val_pred\n",
    "\n",
    "      val_acc = accuracy_score( train_3.iloc[val_idx]['target'].values, torch.round(val_preds.cpu()))\n",
    "      val_roc = roc_auc_score( train_3.iloc[val_idx]['target'].values, val.preds.cpu())\n",
    "\n",
    "      print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n",
    "            epoch + 1, \n",
    "            epoch_loss, \n",
    "            train_acc, \n",
    "            val_acc, \n",
    "            val_roc, \n",
    "            str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n",
    "\n",
    "      scheduler.step(val_roc)\n",
    "\n",
    "      if val_roc >= best_val:\n",
    "        best_val = val_roc\n",
    "        torch.save(model, model_path)\n",
    "  \n",
    "  model = torch.load(model_path)\n",
    "  model.eval()\n",
    "  val_preds = torch.zeros((len(val_idx), 1), dtpe = torch.float32, device=device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for j, (x_val, y_val) in enumerate(val_loader):\n",
    "      x_val[0] = torch.tensor(x_val[0], device = device, dtype= torch.float32)\n",
    "      x_val[1] = torch.tensor(x_val[1], device = device, dtype= torch.float32)\n",
    "      y_val    = torch.tensor(y_val   , device = device, dtype= torch.float32)\n",
    "\n",
    "      z_val = model(x_val)\n",
    "      val_pred = torch.sigmoid(z_val)\n",
    "      val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "    oof[val_idx] = val_preds.cpu().numpy()\n",
    "      \n",
    "    for i, x_test in enumerate(test_loader):\n",
    "      x_test[0] = torch.tensor(x_test[0], device = device, dtype = torch.float32)\n",
    "      x_test[1] = torch.tensor(x_test[1], device = device, dtype = torch.float32)\n",
    "      z_test    = model(x_test)\n",
    "      z_test    = torch.sigmoid(z_test)\n",
    "      z_test = torch.sigmoid(z_test)\n",
    "      preds[i*x_test[0].shape[0]:i*x_test[0].shape[0] + x_test[0].shape[0]] += z_test\n",
    "\n",
    "  del train, val, train_loader, val_loader, x, y, x_val, y_val\n",
    "  gc.collect\n",
    "\n",
    "preds /= skf.n_splits"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Melanoma Detection",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
